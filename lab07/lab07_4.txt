a.
1.
median income is not clear what scale is used
max house value is 500.0 which does not seem organic
rooms per person has some unrealistic large outliers

2.
splitting California along a simple line will result with two dataframes with different statistical characteristics
since housing values in California are not distributed evenly

3.
randomizing the dataset before chopping it in half gives two sets with approximately the same characteristics

4.

  # 1. Create input functions.
  training_input_fn = lambda: my_input_fn(
      training_examples,
      training_targets["median_house_value"],
      batch_size=batch_size)
  predict_training_input_fn = lambda: my_input_fn(
      training_examples,
      training_targets["median_house_value"],
      num_epochs=1,
      shuffle=False)
  predict_validation_input_fn = lambda: my_input_fn(
      validation_examples, validation_targets["median_house_value"],
      num_epochs=1,
      shuffle=False)

    # 2. Take a break and compute predictions.
    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)
    training_predictions = np.array([item['predictions'][0] for item in training_predictions])

    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)
    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])

linear_regressor = train_model(
    # TWEAK THESE VALUES TO SEE HOW MUCH YOU CAN IMPROVE THE RMSE
    learning_rate=0.00001,
    steps=500,
    batch_size=1,
    training_examples=training_examples,
    training_targets=training_targets,
    validation_examples=validation_examples,
    validation_targets=validation_targets)

Training model...
RMSE (on training data):
  period 00 : 220.60
  period 01 : 214.01
  period 02 : 207.63
  period 03 : 201.56
  period 04 : 196.00
  period 05 : 190.54
  period 06 : 185.61
  period 07 : 181.58
  period 08 : 177.55
  period 09 : 174.82

5.
california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")
test_examples = preprocess_features(california_housing_test_data)
test_targets = preprocess_targets(california_housing_test_data)

predict_test_input_fn = lambda: my_input_fn(
      test_examples,
      test_targets["median_house_value"],
      num_epochs=1,
      shuffle=False)

test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)
test_predictions = np.array([item['predictions'][0] for item in test_predictions])

root_mean_squared_error = math.sqrt(
    metrics.mean_squared_error(test_predictions, test_targets))

print("Final RMSE (on test data): %0.2f" % root_mean_squared_error)

Final RMSE (on test data): 161.20

b.
The purpose of creating validation and test sets is to verify the general applicability of your model. Creating a test
set allows you to verify that the model works with new data that your model has not been trained with. Constantly
checking against a training set can cause you model to fit to the peculiarities of the test set, so we can create
a third set which we check against to validate the model while we train it, and only once it fits pretty close to
the validation set do we compare against the test set. It is very important that the test and validation sets are
kept separate from the training set, but are selected randomly from your data so that they are representational
of the whole data set.
