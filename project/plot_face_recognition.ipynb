{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "\n# Faces recognition example using eigenfaces and SVMs\n\n\nThe dataset used in this example is a preprocessed excerpt of the\n\"Labeled Faces in the Wild\", aka LFW_:\n\n  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n\n\nExpected results for the top 5 most represented people in the dataset:\n\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\n                   precision    recall  f1-score   support\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\n     Ariel Sharon       0.67      0.92      0.77        13\n     Colin Powell       0.75      0.78      0.76        60\n  Donald Rumsfeld       0.78      0.67      0.72        27\n    George W Bush       0.86      0.86      0.86       146\nGerhard Schroeder       0.76      0.76      0.76        25\n      Hugo Chavez       0.67      0.67      0.67        15\n       Tony Blair       0.81      0.69      0.75        36\n\n      avg / total       0.80      0.80      0.80       322\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d \u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\nTotal dataset size:\nn_samples: 1288\nn_features: 1850\nn_classes: 7\nExtracting the top 150 eigenfaces from 966 faces\n",
            "done in 1.155s\nProjecting the input data on the eigenfaces orthonormal basis\ndone in 0.037s\nFitting the classifier to the training set\n",
            "done in 44.073s\nBest estimator found by grid search:\nSVC(C\u003d1000.0, cache_size\u003d200, class_weight\u003d\u0027balanced\u0027, coef0\u003d0.0,\n  decision_function_shape\u003d\u0027ovr\u0027, degree\u003d3, gamma\u003d0.005, kernel\u003d\u0027rbf\u0027,\n  max_iter\u003d-1, probability\u003dFalse, random_state\u003dNone, shrinking\u003dTrue,\n  tol\u003d0.001, verbose\u003dFalse)\nPredicting people\u0027s names on the test set\ndone in 0.050s\n                   precision    recall  f1-score   support\n\n     Ariel Sharon       0.86      0.46      0.60        13\n     Colin Powell       0.83      0.87      0.85        60\n  Donald Rumsfeld       0.89      0.63      0.74        27\n    George W Bush       0.83      0.98      0.90       146\nGerhard Schroeder       0.95      0.80      0.87        25\n      Hugo Chavez       0.90      0.60      0.72        15\n       Tony Blair       1.00      0.81      0.89        36\n\n        micro avg       0.86      0.86      0.86       322\n        macro avg       0.89      0.73      0.79       322\n     weighted avg       0.87      0.86      0.85       322\n\n[[  6   1   0   6   0   0   0]\n [  1  52   1   5   0   1   0]\n [  0   2  17   8   0   0   0]\n [  0   3   0 143   0   0   0]\n [  0   1   0   4  20   0   0]\n [  0   3   0   2   1   9   0]\n [  0   1   1   5   0   0  29]]\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "\u003cFigure size 720x720 with 12 Axes\u003e"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": "\u003cFigure size 720x720 with 12 Axes\u003e"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from time import time\nimport logging\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\n\nprint(__doc__)\n\n# Display progress logs on stdout\nlogging.basicConfig(level\u003dlogging.INFO, format\u003d\u0027%(asctime)s %(message)s\u0027)\n\n\n# #############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\n\nlfw_people \u003d fetch_lfw_people(min_faces_per_person\u003d70, resize\u003d0.4)\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w \u003d lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX \u003d lfw_people.data\nn_features \u003d X.shape[1]\n\n# the label to predict is the id of the person\ny \u003d lfw_people.target\ntarget_names \u003d lfw_people.target_names\nn_classes \u003d target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)\n\n\n# #############################################################################\n# Split into a training set and a test set using a stratified k fold\n\n# split into a training and testing set\nX_train, X_test, y_train, y_test \u003d train_test_split(\n    X, y, test_size\u003d0.25, random_state\u003d42)\n\n\n# #############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components \u003d 150\n\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 \u003d time()\npca \u003d PCA(n_components\u003dn_components, svd_solver\u003d\u0027randomized\u0027,\n          whiten\u003dTrue).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))\n\neigenfaces \u003d pca.components_.reshape((n_components, h, w))\n\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 \u003d time()\nX_train_pca \u003d pca.transform(X_train)\nX_test_pca \u003d pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n\n\n# #############################################################################\n# Train a SVM classification model\n\nprint(\"Fitting the classifier to the training set\")\nt0 \u003d time()\nparam_grid \u003d {\u0027C\u0027: [1e3, 5e3, 1e4, 5e4, 1e5],\n              \u0027gamma\u0027: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf \u003d GridSearchCV(SVC(kernel\u003d\u0027rbf\u0027, class_weight\u003d\u0027balanced\u0027),\n                   param_grid, cv\u003d5, iid\u003dFalse)\nclf \u003d clf.fit(X_train_pca, y_train)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n\n\n# #############################################################################\n# Quantitative evaluation of the model quality on the test set\n\nprint(\"Predicting people\u0027s names on the test set\")\nt0 \u003d time()\ny_pred \u003d clf.predict(X_test_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nprint(classification_report(y_test, y_pred, target_names\u003dtarget_names))\nprint(confusion_matrix(y_test, y_pred, labels\u003drange(n_classes)))\n\n\n# #############################################################################\n# Qualitative evaluation of the predictions using matplotlib\n\ndef plot_gallery(images, titles, h, w, n_row\u003d3, n_col\u003d4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize\u003d(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom\u003d0, left\u003d.01, right\u003d.99, top\u003d.90, hspace\u003d.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap\u003dplt.cm.gray)\n        plt.title(titles[i], size\u003d12)\n        plt.xticks(())\n        plt.yticks(())\n\n\n# plot the result of the prediction on a portion of the test set\n\ndef title(y_pred, y_test, target_names, i):\n    pred_name \u003d target_names[y_pred[i]].rsplit(\u0027 \u0027, 1)[-1]\n    true_name \u003d target_names[y_test[i]].rsplit(\u0027 \u0027, 1)[-1]\n    return \u0027predicted: %s\\ntrue:      %s\u0027 % (pred_name, true_name)\n\nprediction_titles \u003d [title(y_pred, y_test, target_names, i)\n                     for i in range(y_pred.shape[0])]\n\nplot_gallery(X_test, prediction_titles, h, w)\n\n# plot the gallery of the most significative eigenfaces\n\neigenface_titles \u003d [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}